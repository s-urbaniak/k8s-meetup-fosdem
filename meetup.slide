Infrastructure components for Kubernetes deployments

Feb 2, 2018

Sergiusz Urbaniak
Senior Software Engineer, Gesundheitscloud
sergiusz.urbaniak@gmail.com

* whoami

- Senior Software Engineer at Gesundheitscloud
- ex-CoreOS
- ex-Mesosphere

Mostly backend and low level development.

I really like *Go*, lower level semantics, and *Kubernetes*!

* Alex Somesan

- AWS veteran (you can see his scars)
- Terraform magician
- Azure improviser

* Background

_A_typical_monday_at_CoreOS_

"Hey Alex, Serge, can you please build a new Tectonic (k8s) installer ..."

* Background

"Hey Alex, Serge, can you please build a new Tectonic (k8s) installer ..."

- for AWS

* Background

"Hey Alex, Serge, can you please build a new Tectonic (k8s) installer ..."

- for AWS
- and Azure
- and Openstack
- and VMWare
- and GCP

* Background

"Hey Alex, Serge, can you please build a new Tectonic (k8s) installer ..."

- for AWS
- and Azure
- and Openstack
- and VMWare
- and GCP
- oh ... don't forget Baremetal

* ok ...

.image https://media.giphy.com/media/ZsCQeG12xHIzu/giphy.gif _ 700

* How to solve this?

When in doubt, ask Kelsey!

.link https://github.com/kelseyhightower/kubernetes-the-hard-way

.image Troll-Face.jpg _ 200

* ... MEH :<

.image hard-way-2.png _ 900

* Automate all the things!

.image https://media1.giphy.com/media/Yxoeu3U5wVYVG/giphy.gif _ 700

* NIH - Infrastructure as code

.image terraform.png _ 700

- `HCL` - Hashicorp Configuration language
- `ICL` - Interpolation configuration language

* Bulding blocks

- Compute
- Storage
- Network

* Compute

"profiles"

- etcd
- master
- worker

* etcd

- Hosts etcd
- Leverages `etcd-member.service`
- Need a cluster of 1, 3, 5, ...

* etcd discovery

1. DNS (SRV records)
2. etcd Discovery service
3. Static

.link https://coreos.com/etcd/docs/latest/v2/clustering.html

* Pros/Cons

1. DNS (SRV records)

*Pro*: DNS dependency only

*Con*: Only one cluster per domain

* Pros/Cons

2. etcd discovery service

*Pro*: No chicken-egg problem with DNS

*Con*: Need a etc discover service, which needs etcd ;-)

* Pros/Cons

3. etcd static discovery (static hostnames)

*Pro*: DNS dependency only

*Con*: DNS names must remain stable

* Example

  [Service]
  Environment="ETCD_IMAGE_TAG=${version}"
  ExecStart=
  ExecStart=/usr/lib/coreos/etcd-wrapper gateway start \
      --listen-addr=127.0.0.1:2379 \
      --endpoints=${endpoints}

* Master

- API server
- scheduler
- controller manager
- kubelet
- proxy

additional control plane daemons:

- (network) flannel, calico
- (self-hosted recovery) checkpointer

* Master

Two deployment methodologies:

- Self-hosted
- Static

* Self hosted deployment using bootkube

*Limitation*:

- bootkube can run on at most one machine.
- We call that machine "bootstrap node".

* Self-hosted deployment

- *Active*: Copy bootstrap assets to target machine

  terraform apply
  ssh core@master1 "bootkube start"

* Self-hosted deployment

- *Passive*: Let master machine decide

"Poor man's master election":

1. Get my machine ID: *id_m*
2. Get all machine IDs: *IDs*
3. Is *id_m*==*min(IDs)* ?

4. If *yes*, start bootkube
5. If *no*, _exit(0)_

* Worker

- kubelet
- proxy
- your workload

additional control plane daemons:
- (network) flannel, calico

* Azure

.code vm-azure.tf

* Vultr

.code vm-vultr.tf

* AWS

.code vm-aws.tf

"An Auto Scaling group contains a collection of VM (EC2) instances that share similar characteristics and are treated as a logical grouping for the purposes of instance scaling and management."

.link https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html

* Machine "profiles"

- Ignition
- Cloud Init

"*Ignition* is a ... provisioning utility ... At the the most basic level, it is a tool for manipulating disks during early boot.

This includes partitioning disks, formatting partitions, writing files (regular files, systemd units, networkd units, etc.), and configuring users."

"*Cloud-init* is the defacto multi-distribution package that handles early initialization of a cloud instance."

* Ignition JSON

.code ignition.json

Please ... don't write this by hand, use this:

.link https://github.com/coreos/container-linux-config-transpiler

.code ignition.ct

* Ignition + Terraform = ❤

.code ignition.tf

`terraform`apply` => Generates Ignition JSON

Also:

.link https://github.com/coreos/terraform-provider-ct

* Problem

Ignition JSON is distributed via cloud _userdata_.

*Concerns*
- Security
- Immutability
- Size constraints (16kB on AWS)

*Solution*
- Distribute userdata via object storage, i.e. S3, https
- Optional: delete userdata after installation

* Storage

*Block*Storage*
- Workload storage
- Beware of cloud-provider support in Kubernetes!
- Watch for bugs/vulnerabilities

*Object*Storage*
- Distribution of Ignition data
- Distribution of deployment assets

* Network

.image networks.jpeg _ 600

* Network

- Routes
- Load Balancing
- Firewall (Security Groups)
- DNS
- L2 vs L3
- Overlay networking

oh my ...

* Let's step back, challanges are:

1. Machine-to-Machine

   10.1.0.0/16

2. Pod-to-Pod ([[https://kubernetes.io/docs/concepts/cluster-administration/networking/]])

   10.2.0.0/16

3. Service network

   10.3.0.0/16   

4. Ingress:

- public ingress
- k8s API (optional)

* The simple one

- Public
Machines get public IPs assigned.
Can be reached from the outside.

- Private
Machines get cluster internal IPs assigned.
Cannot be reached from the outside.

* Software defined network topology

- AWS VPC
- Azure Virtual Network

* AWS ... o.O

.image aws-pvc.png _ 700

* AWS network a la Johannes Ziemke aka "fish"

.image fish-net.png _ 400

.link https://5pi.de/2018/02/01/kubecfn-cloudformation-installer-for-reasonably-secure-multi-master-kubernetes-cluster/

* DNS

Records (A, AAAA ftw):

- Ingress: _public_
- API server: _private,_optionally_public_
- etcd: _private_
- Master nodes: _private_
- Worker nodes: _private_

* DNS

- Azure
- DDNS (RFC2136)
- Designate
- GCP
- PowerDNS
- Route53

*Baremetal*: problematic :<

* DNS - split horizon

.image https://i.ytimg.com/vi/ZhesewjOZEk/maxresdefault.jpg _ 600

"In computer networking, split-horizon DNS, split-view DNS, split-brain DNS, or split DNS is the facility of a Domain Name System (DNS) implementation to provide different sets of DNS information, usually selected by the source address of the DNS request."

.link https://en.wikipedia.org/wiki/Split-horizon_DNS

* DNS - AWS

.code dns.tf

* Load Balancing

Cloud-providers:

- AWS: ELB, ALB
- Azure Load Balancer

Cheapo providers:

- DIY - deployed as VMs
- Cloudflare (via a neat DNS trick)

* Thanks!

.image kermit.gif _ 800
